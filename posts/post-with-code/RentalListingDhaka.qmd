---
title: "A Geospatial Analysis of Rental Price of Apartments in Dhaka"
author: "Fargana Islam"
date: "2023-03-01"
categories: [news, code, analysis]
image: "dhaka_3d.png"
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

A snapshot of the final 3D Map

![](dhaka_3d.png)

Libraries That We Need

```{r message=FALSE}
library(sf)
library(raster)
library(dplyr)
library(spData)
library(terra)
library(OpenStreetMap)
library(osmdata)
library(leaflet)
```

Loading the shape files of three different layers of administrative distribution.

```{r message=FALSE}
shape_file = st_read("bgd_admbnda_adm0_bbs_20201113.shp")

shape_file_2 = st_read("bgd_admbnda_adm2_bbs_20201113.shp")

shape_file_3 = st_read("bgd_admbnda_adm3_bbs_20201113.shp")
```

Only keeping the ADMIN3 areas that are situated in the Dhaka metropolitan area.

```{r message=FALSE}
shape_file_3 = shape_file_3 %>% subset(ADM2_EN == 'Dhaka')
shape_file_3 = shape_file_3 %>% filter(Shape_Area < 1.00e-02)
ADM3_list <- as.vector(st_drop_geometry(shape_file_3['ADM3_EN']))[['ADM3_EN']]
```

Load ADMIN4 areas and keep only those that are inside the same area as ADM3_list

```{r message=FALSE}
shape_file_4 = st_read("shape_file_4_small.shp")

shape_file_4 = shape_file_4 %>% subset(ADM2_EN == 'Dhaka') 
shape_file_4p = shape_file_4 %>% subset(ADM3_EN %in% ADM3_list)
```

Visualizing the map on leaflet

```{r}

bbox_val <- st_bbox(shape_file_4p)

(m <- leaflet() %>%
  addTiles() %>% addProviderTiles("Stamen.TonerLite", group = "Toner Lite") %>% 
  addProviderTiles("Stamen.TonerHybrid", group = "Toner Hybrid") %>% 
  addProviderTiles("Stamen.Watercolor", group = "Watercolor") %>% 
  addProviderTiles("OpenStreetMap.HOT", group = "Humanitarian") %>% 
  addTiles(options = providerTileOptions(noWrap = TRUE), group = "Default") %>% 
  addProviderTiles("CartoDB.DarkMatterNoLabels", group = "Dark Matter") %>% 
  # addMarkers(lng = dhaka_long, lat = dhaka_lat, popup='Dhaka') %>% 
  # addRectangles(bbox_val[[1]], bbox_val[[2]], bbox_val[[3]], bbox_val[[4]]) %>%
  addPolygons(data = shape_file_3, fillOpacity = 0.1, label = ~ADM3_EN, weight=1.5,
              labelOptions = labelOptions(noHide = TRUE, textOnly = TRUE, style = list("font-size"="8px", "color"="white"))
              ))
```

Read rental price data

```{r}
property_data <- read.csv('property_listing_data_in_Bangladesh.csv')
summary(property_data)
```

Let's fix the incorrect spelling of the column names.

```{r}
property_data <- property_data %>% rename(address = adress) %>% rename(floorPlan = flooPlan)
```

Initially we are only concerned with the following columns: 'adress', 'area', 'beds', 'bath', 'price'. Let's look at a few rows to get a good idea. ~~Later, I will use the trick from the link <https://www.cararthompson.com/posts/2022-09-09-automating-sentences-with-r/> to make the above list more dynamic~~

```{r}
head(property_data[c('address', 'area', 'beds', 'bath', 'price')])
```

Let's count how many of the entries are actually in Dhaka.

```{r}
total_num_of_entries <- count(property_data)
(num_of_entries_in_dhaka <- grepl("Dhaka", property_data$address) %>% sum())
```

So, about `r round(100 * num_of_entries_in_dhaka /total_num_of_entries, digits =1)` % of the entries are from Dhaka. That is good for us. Let's filter the other entries from property_data.

```{r}
property_data <- property_data %>% subset(grepl("Dhaka", property_data$address))
```

One thing to note is that property_data does not have any spatial information. The address is a string that one is tempted to look up in a web mapping platform. In fact, I am just going to do that using Google Maps API. However, I cannot disclose my API in the open web. So as a compromise, I will write a function called pseudo_mutate_geocode that will essentially simulate the behavior of ggmap::mutate_geocode. In order to do that, I called the actual mutate_geocode function and queried Google Maps with the addresses listed in property_data. I stored the query output in a new dataframe and saved it to a csv file. The pseudo_mutate_geocode function actually reads from that csv file to simulate the same behavior. However, if you want to query Google Maps using your own API key, that option is given to you as well. All you have to do is set the api_key variable's value to your API key.

```{r}
pseudo_mutate_geocode <- function(data, location) {
  left_join(data, read.csv('cached_google_map_query.csv')[c("address", "lon", "lat")], by = location)
}

api_key <- "NO_API_KEY_PROVIDED"
if (api_key == "NO_API_KEY_PROVIDED") {
  head(property_data <- property_data %>% pseudo_mutate_geocode("address"))[c("address", "lon", "lat")]
} else {
  library(ggmap)
  register_google(api_key)
  head(property_data <- property_data %>% mutate_geocode(address))[c("address", "lon", "lat")]
}
```

```{r}
head(property_data[c('address', 'lon', 'lat', 'area', 'beds', 'bath', 'price')])
```

Now I use the lon and lat attribute as location to convert the dataframe into an sf. I also add ADM4_PCODE for each row from the shape_file_4p sf.

```{r}
property_data_sf <- st_as_sf(property_data, coords=c("lon", "lat"), crs = 4326)
(number_of_rows <- count(property_data_sf)[[1]])
```

After the conversion, we have `r number_of_rows` left. That means the google map query could not find location value for the other `r count(property_data)[[1]] - number_of_rows` rows.

Now let's try to see which ADMIN4 area each of this location point is situated in.

```{r}
property_data_sf <- st_join(property_data_sf, shape_file_4p['ADM4_PCODE'], st_intersects, left=TRUE)
```

Let's count the number of rows left na values we got in ADM4_PCODE when st_join could not find any admin area in which the rental property is located.

```{r}
sum(is.na(property_data_sf$ADM4_PCODE))
```

That is really good. This means we don't have to filter any of the rows for now.

Now let's look at the other non-spatial attributes in property_data. Previously, we have seen all the columns are actually character strings even though some of them could benefit from being converted to numeric. There are also categorical attributes such as type and purpose. Let's look at what are the unique possible values of these attributes and their frequencies. The columns beds and bath are not exactly categorical but they are integers and looking at their possible values could also be helpful.

```{r}
lapply(property_data_sf[c('type', 'purpose', 'beds', 'bath')] %>% st_drop_geometry(), table)
```

Looking at the type attribute we can see that almost all the entries are apartments. Even though we have some building and duplex rows, they are likely to skew the rent distribution. That's why I filter entries that are not apartments.

```{r}
property_data_sf <- property_data_sf %>% filter(type == 'Apartment')
```

All the apartments are for rent so we don't have to do anything with the purpose attribute.

'1 Bed' is the only value that cannot be easily converted to numeric. Same goes for '1 Bath'. Let's delete the non-numeric portion in those cases using gsub. After that we convert them to numeric.

```{r}
property_data_sf$beds <- gsub(pattern = '1 Bed', replacement= '1', property_data_sf$beds) %>% as.numeric()
property_data_sf$bath <- gsub(pattern = '1 Bath', replacement= '1', property_data_sf$bath) %>% as.numeric()
```

area and price are in character string as well and we need to convert them to numeric. We need to first identify the possible word suffixes in these attributes. Let's use regex \[0-9\] to delete the numeric portion and see all the unique suffixes.

```{r}
(area_suffixes <- gsub("[0-9]", "", property_data_sf$area) %>% table())
```

We have `r area_suffixes[[1]]` rows with no suffixes and other rows contain sqft as the suffix. We also have to get rid of the ',' between the digits.

```{r}
property_data_sf$area <- as.numeric(property_data_sf$area %>% gsub(' sqft', '', .) %>% gsub(',', '', .))
```

Now let's find out the suffixes in price.

```{r}
(price_suffixes <- gsub("[0-9]", "", property_data_sf$price) %>% table())
```

This time we have two suffixes and depending on which of them is present, we need to multiply the numeric portion with 100000 or 1000. Let's use a combination of grepl and gsub to achieve this.

```{r}
property_data_sf$rent <- property_data_sf$price %>%
                         gsub(" Thousand", "", .) %>%
                         gsub(" Lakh", "", .) %>%
                          as.numeric() *
                         (1000*(property_data_sf$price %>% grepl(" Thousand", .)) 
                           +100000*(property_data_sf$price %>% grepl(" Lakh", .)))
```

I rename this as rent since it suits the context better.

Let's look at the summary of the 4 numerical attributes.

```{r}
summary(property_data_sf[c('beds', 'bath', 'area', 'rent')] %>% st_drop_geometry())
```

We have some na values in area. I don't want to remove these rows yet, as there could be a possibility that the attributes are higly correlated and in that case we can interpolate area value for these rows.

Let's look at the correlation matrix of the 4 attributes.

```{r}
cor(property_data_sf[c('beds', 'bath', 'area', 'rent')] %>% filter(!is.na(area)) %>%  st_drop_geometry())
```

Interestingly, we got a high correlation between the beds, bath, and rent attribute but area is loosely correlated with these 3. Normally, area and rent are presumed to be highly correlated. However, in a dense metropolitan city, rent depends on numerous other factors. But if that were the case, the correlation would not have been so high between rent, beds, and bath. The area attribute might require some sanitization.

Let's first look at a boxplot of area \~ beds to get some idea. I choose beds as the x axis because it has only 6 possible values and a more important descriptor of a rental property than the number of baths.

```{r}
boxplot(area ~ beds, property_data_sf, horizontal=TRUE)
```

area seems to have a longer positive tail than the negative tail in each subgroup. 12000 sqft is unusually large for a 2/3 bedroom apartment. (To put that into perspective, a basketball court is 4700 sqft). Keeping in mind that these entries are originally created by the property owners from a third world country, it might be the case that some of the values were incorrectly put down. Let's look at additional attributes of a single row to see whether we can cross-check.

```{r}
cat(paste(sprintf("%s = %s", 
                  names(property_data[1,]), 
                  as.character(property_data[1,])), 
          collapse = "\n"))
```

First thing to notice here is that the area information is embedded in the title. The second thing is that the two information do not match even though the difference is small. Let's quickly look at how many entries actually have the "sq" or "ft" pattern in them.

```{r}
(area_embedded_in_title <- property_data_sf$title %>% tolower() %>% grepl(" sq| ft", .) %>% summary())
```

About `r 100 * as.numeric(area_embedded_in_title[["TRUE"]]) / (as.numeric(area_embedded_in_title[["TRUE"]]) + as.numeric(area_embedded_in_title[["FALSE"]]))` % of the rows have the area value embedded in the title. That is even more than the number of rows that have a valid value in the area attribute (`r property_data_sf %>% filter(!is.na(area)) %>% nrow()` ). Let's try to extract that information.

Let's look at a few title first that fits the pattern.

```{r}
(title_vector <- property_data_sf[(property_data_sf$title %>% tolower() %>% grepl(" sq| ft", .)),]$title) %>% head(10)
```

The area size precedes the word containing sq/ft in all the 10 instances above. If we tokenize a title by splitting the string by whitespace and find the index of the token containing sq/ft, then one less than that index is what we are looking for. Let's define a function that will do this for us.

```{r}
extract_area <- function(string) {
  tokens <- unlist(strsplit(tolower(string), " "))
  indices <- which(grepl("^sq|^ft", tokens[2:length(tokens)]))
  # return(length(indices))
  index <- indices[1] + 1
  # return(index)
  # return(tokens[index-1])
  area_size <- gsub("[^[:digit:]]", "", tokens[index-1])
  area_size <- gsub(',', '', area_size)
  return(as.numeric(area_size))
}
```

Before applying it on property_data_sf, let's verify it's effectiveness in title_vector. I apply extract_area on title_vector and summarize the result.

```{r}
#extracted_areas <- purrr::map(title_vector, purrr::possibly(.f = extract_area, otherwise = NA))
extracted_areas <- unlist(lapply(title_vector, extract_area))
summary(extracted_areas)
```

From the summary, it looks like we have only 1 NA value which means we could not extract area information from that row. Let's see the title of that row.

```{r}
title_vector[extracted_areas %>% is.na()]
```

"Tokyo Square" is a residential area in Dhaka City and this threw off the extract_area function which was unable to convert "Tokyo" to numeric. This is an acceptable failure.

Now, let's modify the function extract_area to make it work in cases where there is no sq/ft in the title and after that we will directly apply it on the title attribute of property_data_sf.

```{r}
extract_area <- function(string) {
  tokens <- unlist(strsplit(tolower(string), " "))
  indices <- which(grepl("^sq|^ft", tokens[2:length(tokens)]))
  if (length(indices)<1) {
    return(NA)
  }
  # return(length(indices))
  index <- indices[1] + 1
  # return(index)
  # return(tokens[index-1])
  area_size <- gsub("[^[:digit:]]", "", tokens[index-1])
  area_size <- gsub(',', '', area_size)
  return(as.numeric(area_size))
}
```

```{r}
property_data_sf$area_extracted <- unlist(lapply(property_data_sf$title, extract_area))
summary(property_data_sf$area_extracted)
```

Let's see the correlation of area_extracted with other 3 attributes.

```{r}
cor(property_data_sf[c('beds', 'bath', 'area_extracted', 'rent')] %>% filter(!is.na(area_extracted)) %>%  st_drop_geometry())
```

Awesome! The new area is highly correlated with beds, bath, and rent. Let's look at the boxplot of area_extracted \~ beds to get an idea of what changed.

```{r}
boxplot(area_extracted ~ beds, property_data_sf, horizontal=TRUE)
```

The positive tail in each group has shrunk and the values make realistic sense. The following is my hypothesis on why area_extracted turned out to be more realistic than the original column area. Title is a character string and it represents a summary of the property at a glance. That's why most property owners were careful in writing it down. The area information was a numeric field that received less attention and as a result generated unreliable values. We will proceed with area_extract so let's rename the variables.

```{r}
property_data_sf <- property_data_sf %>% rename(area_from_data = area) %>% rename(area = area_extracted)
```

`r sum(!is.na(property_data_sf$area))` is enough records for us to work with for now. On a later update, I will try to do geospatial interpolation to find area of the missing values.

The usual approach to apartment rental cost analysis is to compare rent per square feet of the data entries. Let's mutate a rent_per_sqft column.

```{r}
property_data_sf$rent_per_sqft <- property_data_sf$rent / property_data_sf$area
```

We want to do a comparison among the ADMIN4 areas in term of rent_per_sqft. Let's group the data by ADM4_PCODE that we added before and calculate mean of the rent_per_sqft for each ADMIN4 area.

```{r}
mean_rent_per_sqft <- property_data_sf %>%
  st_drop_geometry() %>%
  group_by(ADM4_PCODE) %>%
  summarise(rent_per_sqft = mean(rent_per_sqft, na.rm=TRUE))
summary(mean_rent_per_sqft$rent_per_sqft)
```

There are 2 NA values which means for 2 areas we had no entries with a valid rent_per_sqft value. Let's drop those 2 areas from mean_rent_per_sqft.

```{r}
mean_rent_per_sqft <- mean_rent_per_sqft %>% filter(!is.na(rent_per_sqft))
```

~~\[NOTE: I want to add a boxplot/raincloud of rent_per_sqft grouped by ADM3_PCODE later\]~~

We want this information to actually be in the shape_file_4p sf. Let's copy it there and visualize.

```{r}
shape_file_4p$rent_per_sqft <- mean_rent_per_sqft$rent_per_sqft[match(shape_file_4p$ADM4_PCODE, mean_rent_per_sqft$ADM4_PCODE)]
plot((shape_file_4p %>% filter(!is.na(rent_per_sqft)))['rent_per_sqft'])
```

Few things to note here.

The rent_per_sq_ft is homogeneous across most regions except for a few ADMIN4 area in the middle. Those belong to the corporate portion of the city. But it is hard to get a sense of the level of the disparity among the areas from the color value.

I expected some of the areas at the periphery to not have enough information which turned out to be true. Looking at the south portion of the city this effect becomes obvious.

Some middle areas also seem to have no rental property listed. One of them situates the Airport, another is the industrial area.

Now I want to see the rent_per_sqft in a 3D setting to properly assess the disparity.

First, I will load the stars library and rasterize the spatial shape_file_4p.

```{r}
shape_file_4p <- shape_file_4p %>%
  subset(!is.na(rent_per_sqft))
shape_file_4p$rent_per_sqft <- shape_file_4p$rent_per_sqft * 30
```

```{r message=FALSE}
library(stars)
grd = st_as_stars(st_bbox(shape_file_4p %>% dplyr::select(rent_per_sqft, geometry)), nx=2500, ny=2500)
raster_map <- st_rasterize(shape_file_4p %>% dplyr::select(rent_per_sqft, geometry), grd)
```

Let's use the cool rayshader library to plot this raster map.

```{r message=FALSE}
library(rayshader)

r <- rast(raster_map)
elmat = raster_to_matrix(r)
```

Also, I want to overlay a streetmap picture of Dhaka over the rayshader 3D map for the inhabitants to quickly have an idea which portion is actually which area. This is a non-standard step but it ended up looking good so I am keeping it like this. Due to space constraint, I am not adding the steps of actually downloading the picture from ArcGIS but I followed the steps from this brilliant guide [Tutorial: Adding Open Street Map Data to Rayshader Maps in R -- Rayverse Blog (tylermw.com)](https://www.tylermw.com/adding-open-street-map-data-to-rayshader-maps-in-r/).

```{r}
overlay_file <- "images_dhaka.png"
overlay_img <- png::readPNG(overlay_file)
```

Let's finally draw the 3D map.

```{r eval=FALSE}
elmat %>%
  sphere_shade(texture = "imhof2") %>%
  # add_water(detect_water(elmat), color = "desert") %>%
  add_overlay(overlay_img, alphalayer = 1.0) %>%
  # add_overlay(overlay_img_2, alphalayer = 1.0) %>%
  # add_overlay(osm_data) %>%
  add_shadow(ray_shade(elmat, zscale = 3), 0.5) %>%
  add_shadow(ambient_shade(elmat), 0) %>%
  plot_3d(elmat, zscale = 2, fov = 0, theta = 45, zoom = 0.75, phi = 45, windowsize = c(1600, 1600))
```

```{r eval=FALSE}
render_snapshot('~/Desktop/dhaka_3d.jpg')
```
